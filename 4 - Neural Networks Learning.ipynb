{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.io \n",
    "import scipy.misc \n",
    "import matplotlib.cm as cm \n",
    "import random \n",
    "import scipy.optimize \n",
    "import itertools\n",
    "from scipy.special import expit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape:  (5000, 1)\n",
      "x shape:  (5000, 401)\n"
     ]
    }
   ],
   "source": [
    "data = scipy.io.loadmat( 'data/ex4data1.mat' )\n",
    "y = data['y']\n",
    "X = np.insert(data['X'],0,1,axis=1)\n",
    "\n",
    "print(\"y shape: \", y.shape)\n",
    "print(\"x shape: \", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta1 shape: (25, 401)\n",
      "Theta2 shape: (10, 26)\n"
     ]
    }
   ],
   "source": [
    "mat = scipy.io.loadmat( 'data/ex4weights.mat' )\n",
    "Theta1, Theta2 = mat['Theta1'], mat['Theta2']\n",
    "\n",
    "print(\"Theta1 shape: \", Theta1.shape)\n",
    "print(\"Theta2 shape: \", Theta2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural Netword Architecture:\n",
    "input_layer_size = 400\n",
    "hidden_layer_size = 25\n",
    "output_layer_size = 10 \n",
    "n_training_samples = X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def flatten_theta(thetas_list):\n",
    "    flattened_list = [ mytheta.flatten() for mytheta in thetas_list ]\n",
    "    combined = list(itertools.chain.from_iterable(flattened_list))\n",
    "    assert len(combined) == (input_layer_size+1)*hidden_layer_size + \\\n",
    "                            (hidden_layer_size+1)*output_layer_size\n",
    "    return np.array(combined).reshape((len(combined),1))\n",
    "\n",
    "def reshape_theta(flattened_array):\n",
    "    theta1 = flattened_array[:(input_layer_size+1)*hidden_layer_size] \\\n",
    "            .reshape((hidden_layer_size,input_layer_size+1))\n",
    "    theta2 = flattened_array[(input_layer_size+1)*hidden_layer_size:] \\\n",
    "            .reshape((output_layer_size,hidden_layer_size+1))\n",
    "    \n",
    "    return [ theta1, theta2 ]\n",
    "\n",
    "def flattenX(myX):\n",
    "    return np.array(myX.flatten()).reshape((n_training_samples*(input_layer_size+1),1))\n",
    "\n",
    "def reshapeX(flattenedX):\n",
    "    return np.array(flattenedX).reshape((n_training_samples,input_layer_size+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(mythetas_flattened,myX_flattened,myy,mylambda=0.):\n",
    "    mythetas = reshape_theta(mythetas_flattened\n",
    "    myX = reshapeX(myX_flattened)\n",
    "    total_cost = 0.\n",
    "    m = n_training_samples\n",
    "\n",
    "    for irow in range(m):\n",
    "        myrow = myX[irow]\n",
    "        myhs = forward_propagate(myrow,mythetas)[-1][1]\n",
    "        tmpy  = np.zeros((10,1))\n",
    "        tmpy[myy[irow]-1] = 1\n",
    "        mycost = -tmpy.T.dot(np.log(myhs))-(1-tmpy.T).dot(np.log(1-myhs))\n",
    "        total_cost += mycost\n",
    "  \n",
    "    total_cost = float(total_cost) / m\n",
    "    total_reg = 0.\n",
    "    for mytheta in mythetas:\n",
    "        total_reg += np.sum(mytheta*mytheta) \n",
    "    total_reg *= float(mylambda)/(2*m)\n",
    "    return total_cost + total_reg    \n",
    "\n",
    "def forward_propagate(row,Thetas):\n",
    "    features = row\n",
    "    zs_as_per_layer = []\n",
    "    for i in range(len(Thetas)):  \n",
    "        Theta = Thetas[i]\n",
    "        z = Theta.dot(features).reshape((Theta.shape[0],1))\n",
    "        a = expit(z)\n",
    "        zs_as_per_layer.append( (z, a) )\n",
    "        if i == len(Thetas)-1:\n",
    "            return np.array(zs_as_per_layer)\n",
    "        a = np.insert(a,0,1)\n",
    "        features = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28762916516131876\n"
     ]
    }
   ],
   "source": [
    "myThetas = [ Theta1, Theta2 ]\n",
    "print(cost(flatten_theta(myThetas),flattenX(X),y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3844877962428938\n"
     ]
    }
   ],
   "source": [
    "myThetas = [ Theta1, Theta2 ]\n",
    "print(cost(flatten_theta(myThetas),flattenX(X),y,mylambda=1.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 2.1 Sigmoid gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    dummy = expit(z)\n",
    "    return dummy*(1-dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Random initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_theta():\n",
    "    epsilon_init = 0.12\n",
    "    theta1_shape = (hidden_layer_size, input_layer_size+1)\n",
    "    theta2_shape = (output_layer_size, hidden_layer_size+1)\n",
    "    rand_thetas = [ np.random.rand( *theta1_shape ) * 2 * epsilon_init - epsilon_init, \\\n",
    "                    np.random.rand( *theta2_shape ) * 2 * epsilon_init - epsilon_init]\n",
    "    return rand_thetas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Backpropagation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagate(mythetas_flattened,myX_flattened,myy,mylambda=0.):\n",
    "    mythetas = reshape_theta(mythetas_flattened)\n",
    "    myX = reshapeX(myX_flattened)\n",
    "    Delta1 = np.zeros((hidden_layer_size,input_layer_size+1))\n",
    "    Delta2 = np.zeros((output_layer_size,hidden_layer_size+1))\n",
    "    m = n_training_samples\n",
    "    for irow in range(m):\n",
    "        myrow = myX[irow]\n",
    "        a1 = myrow.reshape((input_layer_size+1,1))\n",
    "        temp = forward_propagate(myrow,mythetas)\n",
    "        z2 = temp[0][0]\n",
    "        a2 = temp[0][1]\n",
    "        z3 = temp[1][0]\n",
    "        a3 = temp[1][1]\n",
    "        tmpy = np.zeros((10,1))\n",
    "        tmpy[myy[irow]-1] = 1\n",
    "        delta3 = a3 - tmpy \n",
    "        delta2 = mythetas[1].T[1:,:].dot(delta3)*sigmoid(z2) \n",
    "        a2 = np.insert(a2,0,1,axis=0)\n",
    "        Delta1 += delta2.dot(a1.T) \n",
    "        Delta2 += delta3.dot(a2.T) \n",
    "        \n",
    "    D1 = Delta1/float(m)\n",
    "    D2 = Delta2/float(m)\n",
    "    \n",
    "    D1[:,1:] = D1[:,1:] + (float(mylambda)/m)*mythetas[0][:,1:]\n",
    "    D2[:,1:] = D2[:,1:] + (float(mylambda)/m)*mythetas[1][:,1:]\n",
    "    \n",
    "    return flatten_theta([D1, D2]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattenedD1D2 = backward_propagate(flatten_theta(myThetas),flattenX(X),y,mylambda=0.)\n",
    "D1, D2 = reshape_theta(flattenedD1D2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Gradient checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_gradient(mythetas,myDs,myX,myy,mylambda=0.):\n",
    "    myeps = 0.0001\n",
    "    flattened = flatten_theta(mythetas)\n",
    "    flattenedDs = flatten_theta(myDs)\n",
    "    myX_flattened = flattenX(myX)\n",
    "    n_elems = len(flattened) \n",
    "    for i in range(3):\n",
    "        x = int(np.random.rand()*n_elems)\n",
    "        epsvec = np.zeros((n_elems,1))\n",
    "        epsvec[x] = myeps\n",
    "        cost_high = cost(flattened + epsvec,myX_flattened,myy,mylambda)\n",
    "        cost_low  = cost(flattened - epsvec,myX_flattened,myy,mylambda)\n",
    "        mygrad = (cost_high - cost_low) / float(2*myeps)\n",
    "        print(\"Element: %d. Numerical Gradient = %f. BackProp Gradient = %f.\"%(x,mygrad,flattenedDs[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element: 6167. Numerical Gradient = -0.000014. BackProp Gradient = -0.000014.\n",
      "Element: 5604. Numerical Gradient = -0.000006. BackProp Gradient = -0.000006.\n",
      "Element: 121. Numerical Gradient = 0.000001. BackProp Gradient = 0.000001.\n"
     ]
    }
   ],
   "source": [
    "check_gradient(myThetas,[D1, D2],X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Learning  the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(mylambda=0.):\n",
    "    randomThetas_unrolled = flatten_theta(random_theta())\n",
    "    result = scipy.optimize.fmin_cg(cost, x0=randomThetas_unrolled, fprime=backward_propagate, \\\n",
    "                               args=(flattenX(X),y,mylambda),maxiter=50,disp=True,full_output=True)\n",
    "    return reshape_theta(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainNN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-360c3bcdefd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Training the NN takes about ~70-80 seconds on my machine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlearned_Thetas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'trainNN' is not defined"
     ]
    }
   ],
   "source": [
    "learned_Thetas = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(row,Thetas):\n",
    "    classes = range(1,10) + [10]\n",
    "    output = forward_propagate(row,Thetas)\n",
    "    return classes[np.argmax(output[-1][1])] \n",
    "\n",
    "def accuracy(myX,myThetas,myy):\n",
    "    n_correct, n_total = 0, myX.shape[0]\n",
    "    for irow in xrange(n_total):\n",
    "        if int(predict(myX[irow],myThetas)) == int(myy[irow]): \n",
    "            n_correct += 1\n",
    "    print \"Training set accuracy: %0.1f%%\"%(100*(float(n_correct)/n_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(X,learned_Thetas,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learned_regularized_Thetas = train(mylambda=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(X,learned_regularized_Thetas,y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
